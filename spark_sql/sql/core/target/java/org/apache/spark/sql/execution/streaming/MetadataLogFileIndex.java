package org.apache.spark.sql.execution.streaming;
/**
 * A {@link FileIndex} that generates the list of files to processing by reading them from the
 * metadata log files generated by the {@link FileStreamSink}.
 * <p>
 * param:  userSpecifiedSchema an optional user specified schema that will be use to provide
 *                            types for the discovered partitions
 */
public  class MetadataLogFileIndex extends org.apache.spark.sql.execution.datasources.PartitioningAwareFileIndex {
  public   MetadataLogFileIndex (org.apache.spark.sql.SparkSession sparkSession, org.apache.hadoop.fs.Path path, scala.collection.immutable.Map<java.lang.String, java.lang.String> parameters, scala.Option<org.apache.spark.sql.types.StructType> userSpecifiedSchema)  { throw new RuntimeException(); }
  protected  scala.collection.immutable.Map<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileStatus[]> leafDirToChildrenFiles ()  { throw new RuntimeException(); }
  protected  scala.collection.mutable.LinkedHashMap<org.apache.hadoop.fs.Path, org.apache.hadoop.fs.FileStatus> leafFiles ()  { throw new RuntimeException(); }
  public  org.apache.spark.sql.execution.datasources.PartitionSpec partitionSpec ()  { throw new RuntimeException(); }
  public  void refresh ()  { throw new RuntimeException(); }
  public  scala.collection.Seq<org.apache.hadoop.fs.Path> rootPaths ()  { throw new RuntimeException(); }
}
